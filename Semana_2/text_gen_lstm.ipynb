{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-6.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Apertura de cuentas en Kaggle\n",
        "\n",
        "\n",
        "https://www.kaggle.com/\n",
        "\n",
        "\n",
        "Verificar SMS para tener acceso a GPUs\n",
        "\n",
        "Para SMS verificado sin usar el telefono propio o para abrir varias cuentas :)\n",
        "\n",
        "https://www.freereceivesms.com/\n"
      ],
      "metadata": {
        "id": "SlY3qJOIAqKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generacion de texto con RNN"
      ],
      "metadata": {
        "id": "ovpZyIhNIgoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "WGyKZj3bzf9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install youtube-transcript-api"
      ],
      "metadata": {
        "id": "gpnEplxBr7Jl",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:01:31.817514Z",
          "iopub.status.idle": "2023-06-08T16:01:31.817891Z",
          "shell.execute_reply.started": "2023-06-08T16:01:31.817709Z",
          "shell.execute_reply": "2023-06-08T16:01:31.817726Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "#from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def getVideoCaptions(video_id):\n",
        "    try:\n",
        "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
        "        for transcript in transcript_list:\n",
        "            if transcript.language_code in ['es','es-419']:\n",
        "                auto_generated_transcript = transcript.fetch()\n",
        "                break\n",
        "        texts = [x.get('text') for x in auto_generated_transcript]\n",
        "        starts = [x.get('start') for x in auto_generated_transcript]\n",
        "        result = {'resourceId': video_id,\n",
        "                  'texts': texts,\n",
        "                  'starts': starts,\n",
        "                 }\n",
        "    except:\n",
        "        result = None\n",
        "        print(f'Error {video_id}')\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "yG_n40gFzf9s",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:36.356700Z",
          "iopub.execute_input": "2023-06-08T16:11:36.357042Z",
          "iopub.status.idle": "2023-06-08T16:11:44.362292Z",
          "shell.execute_reply.started": "2023-06-08T16:11:36.357012Z",
          "shell.execute_reply": "2023-06-08T16:11:44.361304Z"
        },
        "trusted": true,
        "outputId": "453ba35f-14c3-46b7-a777-cc3fa8533616"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lectura de la data"
      ],
      "metadata": {
        "id": "UHjdCjDuSvX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data Mises\n",
        "url = \"https://github.com/gauss314/ucema/raw/9290f43cc8be8a932d99c8ac507a5f8811176ddc/mises.pickle\"\n",
        "\n",
        "response = requests.get(url)\n",
        "data = pickle.loads(response.content)"
      ],
      "metadata": {
        "id": "FLixhgoRII57",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:44.364224Z",
          "iopub.execute_input": "2023-06-08T16:11:44.364968Z",
          "iopub.status.idle": "2023-06-08T16:11:45.118626Z",
          "shell.execute_reply.started": "2023-06-08T16:11:44.364936Z",
          "shell.execute_reply": "2023-06-08T16:11:45.117629Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = data\n",
        "text = re.sub(r'[^\\w\\s,.ñ?¿]', '', text)\n",
        "text = text.lower()\n",
        "characters_to_replace = ['ª', 'º', 'à', 'ä', 'ç', 'è', 'ê', 'ë', 'î', 'ô', 'ö', 'ü']\n",
        "\n",
        "for char in characters_to_replace:\n",
        "    text = text.replace(char, '')\n",
        "\n",
        "print(f\"Length of text: {len(text)} characters\")"
      ],
      "metadata": {
        "id": "aavnuByVymwK",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603c7301-c2ae-4a28-cd4a-4012d4fec618",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:45.120197Z",
          "iopub.execute_input": "2023-06-08T16:11:45.120539Z",
          "iopub.status.idle": "2023-06-08T16:11:45.312133Z",
          "shell.execute_reply.started": "2023-06-08T16:11:45.120507Z",
          "shell.execute_reply": "2023-06-08T16:11:45.311040Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Length of text: 2374631 characters\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(text[:500])"
      ],
      "metadata": {
        "id": "Duhg9NrUymwO",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ff406c-aa4c-484c-b862-60d353c88be4",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:45.315048Z",
          "iopub.execute_input": "2023-06-08T16:11:45.315436Z",
          "iopub.status.idle": "2023-06-08T16:11:45.320104Z",
          "shell.execute_reply.started": "2023-06-08T16:11:45.315402Z",
          "shell.execute_reply": "2023-06-08T16:11:45.319234Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "('ludwig von mises liberalismo la tradición clásica trad. juan marcos de la '\n 'fuente epub r1.0 leviatán  loto  03.10.14 www.lectulandia.com  página 3 c '\n 'apítulo  i los fundamentos de una política liberal 1.  l a   propiedad la '\n 'sociedad humana es una asociación de individuos para una acción común. una '\n 'acción común regulada por el principio de la división del trabajo tiene la '\n 'ventaja de una mayor productividad frente a la acción aislada de los '\n 'individuos. si un cierto número de individuos da un marcham')\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Caracteres unicos"
      ],
      "metadata": {
        "id": "yA5ygqlUsVNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f\"{len(vocab)} caracteres unicos\")"
      ],
      "metadata": {
        "id": "IlCgQBRVymwR",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd048aab-6e3a-472d-bf1a-68f8a689b394",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:45.321439Z",
          "iopub.execute_input": "2023-06-08T16:11:45.321976Z",
          "iopub.status.idle": "2023-06-08T16:11:45.363126Z",
          "shell.execute_reply.started": "2023-06-08T16:11:45.321945Z",
          "shell.execute_reply": "2023-06-08T16:11:45.362133Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "47 caracteres unicos\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento del texto"
      ],
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizacion del texto\n",
        "\n",
        "Antes de entrenar debemos convertir el texto en numeros\n",
        "\n",
        "Usando tf.keras.layers.StringLookup, se puede convertir cada carácter en un ID numérico (y viceversa). Solo necesita que el texto se divida en tokens primero."
      ],
      "metadata": {
        "id": "LFjSVAlWzf-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary = list(vocab), mask_token=None\n",
        ")\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary = ids_from_chars.get_vocabulary(), invert=True, mask_token=None\n",
        ")\n",
        "\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "Wd2m3mqkDjRj",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:45.364702Z",
          "iopub.execute_input": "2023-06-08T16:11:45.365096Z",
          "iopub.status.idle": "2023-06-08T16:11:48.204655Z",
          "shell.execute_reply.started": "2023-06-08T16:11:45.365045Z",
          "shell.execute_reply": "2023-06-08T16:11:48.203700Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = 'hola que tal?'\n",
        "chars = tf.strings.unicode_split(example_text, input_encoding=\"UTF-8\")\n",
        "\n",
        "ids = ids_from_chars(chars)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzaZ-H38-oMS",
        "outputId": "6c8b7274-94d7-4505-b102-f7c1bea742e4",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:48.205851Z",
          "iopub.execute_input": "2023-06-08T16:11:48.206207Z",
          "iopub.status.idle": "2023-06-08T16:11:48.256860Z",
          "shell.execute_reply.started": "2023-06-08T16:11:48.206176Z",
          "shell.execute_reply": "2023-06-08T16:11:48.255880Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tf.Tensor([22 29 26 15  1 31 35 19  1 34 15 26 14], shape=(13,), dtype=int64)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_from_ids(ids))"
      ],
      "metadata": {
        "id": "w5apvBDn9Ind",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c7cd1c-6c6f-4010-a54b-639b8325099c",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:48.258050Z",
          "iopub.execute_input": "2023-06-08T16:11:48.258393Z",
          "iopub.status.idle": "2023-06-08T16:11:48.268048Z",
          "shell.execute_reply.started": "2023-06-08T16:11:48.258362Z",
          "shell.execute_reply": "2023-06-08T16:11:48.266938Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tf.Tensor(b'hola que tal?', shape=(), dtype=string)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genero los IDs de todo el dataset"
      ],
      "metadata": {
        "id": "tJIKcYAkL5lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, \"UTF-8\"))\n",
        "all_ids"
      ],
      "metadata": {
        "id": "UopbsKi88tm5",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065beb14-2288-4f5d-e221-b4051a190f26",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:48.269747Z",
          "iopub.execute_input": "2023-06-08T16:11:48.270491Z",
          "iopub.status.idle": "2023-06-08T16:11:49.385076Z",
          "shell.execute_reply.started": "2023-06-08T16:11:48.270454Z",
          "shell.execute_reply": "2023-06-08T16:11:49.384073Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tf.Tensor: shape=(2374631,), dtype=int64, numpy=array([26, 35, 18, ..., 29,  3,  1])>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "qmxrYDCTy-eL",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:49.388572Z",
          "iopub.execute_input": "2023-06-08T16:11:49.388922Z",
          "iopub.status.idle": "2023-06-08T16:11:49.397033Z",
          "shell.execute_reply.started": "2023-06-08T16:11:49.388893Z",
          "shell.execute_reply": "2023-06-08T16:11:49.395950Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(100):\n",
        "    print(chars_from_ids(ids).numpy().decode(\"utf-8\"), end='')"
      ],
      "metadata": {
        "id": "cjH5v45-yqqH",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11f8f5c-5723-43b3-8ce6-e75305227002",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:11:49.398409Z",
          "iopub.execute_input": "2023-06-08T16:11:49.399327Z",
          "iopub.status.idle": "2023-06-08T16:11:49.564701Z",
          "shell.execute_reply.started": "2023-06-08T16:11:49.399290Z",
          "shell.execute_reply": "2023-06-08T16:11:49.563727Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "ludwig von mises liberalismo la tradición clásica trad. juan marcos de la fuente epub r1.0 leviatán ",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genero los lotes"
      ],
      "metadata": {
        "id": "6u3WYPYQNABX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el texto en secuencias de ejemplo.\n",
        "\n",
        "Cada secuencia de entrada contendrá seq_length caracteres del texto.\n",
        "\n",
        "Dividimos el texto en fragmentos de seq_length+1. (El +1 es porque como veremos luego necesitamos una secuencia y su target q es lka misma secuencia desplazada 1 caracter a la derecha)"
      ],
      "metadata": {
        "id": "uRgeGdL7Nk2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 150\n",
        "examples_per_epoch = len(text) // (seq_length + 1)\n",
        "examples_per_epoch"
      ],
      "metadata": {
        "id": "C-G2oaTxy6km",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf140486-8e04-4a13-bcac-5434a7fcf417",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:12:17.615248Z",
          "iopub.execute_input": "2023-06-08T16:12:17.616035Z",
          "iopub.status.idle": "2023-06-08T16:12:17.623903Z",
          "shell.execute_reply.started": "2023-06-08T16:12:17.616001Z",
          "shell.execute_reply": "2023-06-08T16:12:17.622767Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "15726"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:12:18.316368Z",
          "iopub.execute_input": "2023-06-08T16:12:18.316723Z",
          "iopub.status.idle": "2023-06-08T16:12:18.324627Z",
          "shell.execute_reply.started": "2023-06-08T16:12:18.316693Z",
          "shell.execute_reply": "2023-06-08T16:12:18.323673Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy().decode())"
      ],
      "metadata": {
        "id": "QO32cMWu4a06",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe19f16c-151f-4d54-ca01-dd61b33c14b9",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:12:18.932601Z",
          "iopub.execute_input": "2023-06-08T16:12:18.932944Z",
          "iopub.status.idle": "2023-06-08T16:12:18.955709Z",
          "shell.execute_reply.started": "2023-06-08T16:12:18.932915Z",
          "shell.execute_reply": "2023-06-08T16:12:18.954752Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "ludwig von mises liberalismo la tradición clásica trad. juan marcos de la fuente epub r1.0 leviatán  loto  03.10.14 www.lectulandia.com  página 3 c apí\ntulo  i los fundamentos de una política liberal 1.  l a   propiedad la sociedad humana es una asociación de individuos para una acción común. una acció\nn común regulada por el principio de la división del trabajo tiene la ventaja de una mayor productividad frente a la acción aislada de los individuos. \nsi un cierto número de individuos da un marchamo común a la propia acción, sobre la base de la división del trabajo, produce, en igualdad de condicione\ns, no sólo la misma cantidad de cosas que habrían producido cada uno por su cuenta, sino una cantidad muy superior. todo el proceso de civilización del\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desfaso las secuencias"
      ],
      "metadata": {
        "id": "V9kO2SF1NKas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada secuencia de entrada, sus targets contienen la misma longitud de texto, desplazada un carácter a la derecha.\n",
        "\n",
        "Por ejemplo, supongamos que seq_length es 4 y nuestro texto es \"El taco no...\"\n",
        "* La secuencia de entrada sería \"El ta\"\n",
        "* Y la secuencia objetivo sería \"l tac\".\n",
        "\n",
        "usamos tf.data.Dataset.from_tensor_slices para convertir el vector de texto en un flujo de índices de caracteres."
      ],
      "metadata": {
        "id": "hgsVvVxnymwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "9NGu-FkO_kYU",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:12:21.376255Z",
          "iopub.execute_input": "2023-06-08T16:12:21.376617Z",
          "iopub.status.idle": "2023-06-08T16:12:21.381237Z",
          "shell.execute_reply.started": "2023-06-08T16:12:21.376586Z",
          "shell.execute_reply": "2023-06-08T16:12:21.380298Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo para visualizarlo\n",
        "[''.join(x) for x in split_input_target(list(\"El taco no, hace la personal\"))]"
      ],
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac0700b-a795-41c8-c3f4-cab8e435e4d8",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:12:21.689754Z",
          "iopub.execute_input": "2023-06-08T16:12:21.690321Z",
          "iopub.status.idle": "2023-06-08T16:12:21.697117Z",
          "shell.execute_reply.started": "2023-06-08T16:12:21.690288Z",
          "shell.execute_reply": "2023-06-08T16:12:21.696130Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['El taco no, hace la persona', 'l taco no, hace la personal']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo hago para mi dataset\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "B9iKPXkw5xwa",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:12:22.218782Z",
          "iopub.execute_input": "2023-06-08T16:12:22.219480Z",
          "iopub.status.idle": "2023-06-08T16:12:22.277884Z",
          "shell.execute_reply.started": "2023-06-08T16:12:22.219443Z",
          "shell.execute_reply": "2023-06-08T16:12:22.276982Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    pprint.pprint(f\"Input: {text_from_ids(input_example).numpy().decode()}\")\n",
        "    pprint.pprint(f\"Target: {text_from_ids(target_example).numpy().decode()}\")"
      ],
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "741aba9a-1c6e-4c94-81f3-d7605987cb6c",
        "execution": {
          "iopub.status.busy": "2023-06-08T16:12:22.520451Z",
          "iopub.execute_input": "2023-06-08T16:12:22.520797Z",
          "iopub.status.idle": "2023-06-08T16:12:22.558673Z",
          "shell.execute_reply.started": "2023-06-08T16:12:22.520768Z",
          "shell.execute_reply": "2023-06-08T16:12:22.557760Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "('Input: ludwig von mises liberalismo la tradición clásica trad. juan marcos '\n 'de la fuente epub r1.0 leviatán  loto  03.10.14 www.lectulandia.com  página '\n '3 c ap')\n('Target: udwig von mises liberalismo la tradición clásica trad. juan marcos '\n 'de la fuente epub r1.0 leviatán  loto  03.10.14 www.lectulandia.com  página '\n '3 c apí')\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creo los lotes de entrenamiento"
      ],
      "metadata": {
        "id": "MJdfPmdqzf-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "BATCH_SIZE = 192\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = (\n",
        "    dataset.shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "p2pGotuNzf-S",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:32:55.080858Z",
          "iopub.execute_input": "2023-06-08T16:32:55.081239Z",
          "iopub.status.idle": "2023-06-08T16:32:55.106639Z",
          "shell.execute_reply.started": "2023-06-08T16:32:55.081206Z",
          "shell.execute_reply": "2023-06-08T16:32:55.105775Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instancio el modelo"
      ],
      "metadata": {
        "id": "r6oUuElIMgVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings:\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 192\n",
        "rnn_units = 2048"
      ],
      "metadata": {
        "id": "zHT8cLh7EAsg",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T16:32:58.734760Z",
          "iopub.execute_input": "2023-06-08T16:32:58.735310Z",
          "iopub.status.idle": "2023-06-08T16:32:58.744269Z",
          "shell.execute_reply.started": "2023-06-08T16:32:58.735271Z",
          "shell.execute_reply": "2023-06-08T16:32:58.742893Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capas del modelo\n",
        "\n",
        "* tf.keras.layers.Embedding: La capa de entrada. Una tabla de búsqueda entrenable que mapeará cada ID (q representa a un carácter) a un vector con dimensiones \"embedding_dim\"\n",
        "\n",
        "* tf.keras.layers.GRU: Un tipo de RNN con tamaño units=rnn_units, se podria usar una LSTM aca\n",
        "\n",
        "* tf.keras.layers.Dense: La capa de salida, con vocab_size salidas. Emite un logit para cada carácter en el vocabulario. Estos son la log-verosimilitud de cada carácter según el modelo. O sea la probabilidad de que sea cualquiera de los caracteres posibles del vocabulario"
      ],
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class below does the following:\n",
        "- Heredamos desde tf.keras.Model\n",
        "- En el constructor definimos las 3 capas del modelo\n",
        "- Definimos el paso hacia adelante utilizando las capas definidas en el constructor."
      ],
      "metadata": {
        "id": "HtOcRAOmsVNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModelRNN(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = self.embedding(inputs, training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "class MyModelLSTM(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = self.embedding(inputs, training=training)\n",
        "        if states is None:\n",
        "            states = self.lstm.get_initial_state(x)  # LSTM tiene 2 estados.\n",
        "        x, h, c = self.lstm(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, [h, c]\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "wj8HQ2w8z4iO",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T17:27:27.654016Z",
          "iopub.execute_input": "2023-06-08T17:27:27.654816Z",
          "iopub.status.idle": "2023-06-08T17:27:27.668718Z",
          "shell.execute_reply.started": "2023-06-08T17:27:27.654770Z",
          "shell.execute_reply": "2023-06-08T17:27:27.667621Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModelLSTM(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        ")"
      ],
      "metadata": {
        "id": "IX58Xj9z47Aw",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T17:27:30.176524Z",
          "iopub.execute_input": "2023-06-08T17:27:30.177191Z",
          "iopub.status.idle": "2023-06-08T17:27:30.194254Z",
          "shell.execute_reply.started": "2023-06-08T17:27:30.177159Z",
          "shell.execute_reply": "2023-06-08T17:27:30.193375Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(\n",
        "        example_batch_predictions.shape,\n",
        "    )"
      ],
      "metadata": {
        "id": "C-_70kKAPrPU",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bc1304-56d9-45c3-f5dd-27ae184ef3d5",
        "execution": {
          "iopub.status.busy": "2023-06-08T17:27:33.609799Z",
          "iopub.execute_input": "2023-06-08T17:27:33.610172Z",
          "iopub.status.idle": "2023-06-08T17:27:44.181374Z",
          "shell.execute_reply.started": "2023-06-08T17:27:33.610142Z",
          "shell.execute_reply": "2023-06-08T17:27:44.180360Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(192, 150, 48)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El codigo muestra la forma de las predicciones, ejemplo: 64 tamaño del lote, 300 de longitud de cadena y 48 de tamaño de vocabulario que son las posible predicciones"
      ],
      "metadata": {
        "id": "Q6NzLBi4VM4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c757c43b-313a-4a6c-bf61-ab7efbdcc486",
        "execution": {
          "iopub.status.busy": "2023-06-08T17:27:49.766643Z",
          "iopub.execute_input": "2023-06-08T17:27:49.767007Z",
          "iopub.status.idle": "2023-06-08T17:27:49.783029Z",
          "shell.execute_reply.started": "2023-06-08T17:27:49.766975Z",
          "shell.execute_reply": "2023-06-08T17:27:49.782151Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"my_model_lstm_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_3 (Embedding)     multiple                  9216      \n                                                                 \n lstm_1 (LSTM)               multiple                  18358272  \n                                                                 \n dense_3 (Dense)             multiple                  98352     \n                                                                 \n=================================================================\nTotal params: 18,465,840\nTrainable params: 18,465,840\nNon-trainable params: 0\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a tratar la RNN como un simple problema de clasificacion.\n",
        "\n",
        "Dado el estado anterior de la RNN y la entrada en este paso de tiempo, predice la clase del siguiente carácter"
      ],
      "metadata": {
        "id": "YCbHQHiaa4Ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funcion de perdida\n",
        "\n",
        "Usaremos la función de pérdida estándar tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "En este caso se aplica a la última dimensión de las predicciones\n",
        "\n",
        "Debido a que nuestro modelo devuelve logits, necesitamos establecer el indicador from_logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UAjbjY03eiQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "ZOeWdgxNFDXq",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T17:27:55.608995Z",
          "iopub.execute_input": "2023-06-08T17:27:55.609950Z",
          "iopub.status.idle": "2023-06-08T17:27:55.614659Z",
          "shell.execute_reply.started": "2023-06-08T17:27:55.609917Z",
          "shell.execute_reply": "2023-06-08T17:27:55.613524Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Tamaño de las predicciones: \", example_batch_predictions.shape)\n",
        "print(\"Perdida media: \", example_batch_mean_loss.numpy())"
      ],
      "metadata": {
        "id": "4HrXTACTdzY-",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad0eb01-9031-48a9-e033-a627c087ff0b",
        "execution": {
          "iopub.status.busy": "2023-06-08T17:27:56.785981Z",
          "iopub.execute_input": "2023-06-08T17:27:56.786635Z",
          "iopub.status.idle": "2023-06-08T17:27:56.798111Z",
          "shell.execute_reply.started": "2023-06-08T17:27:56.786602Z",
          "shell.execute_reply": "2023-06-08T17:27:56.797034Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Tamaño de las predicciones:  (192, 150, 48)\nPerdida media:  3.8709478\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como recien inicializamos el modelo, no aprendio nada aun, por lo tanto no debería estar demasiado seguro de sí mismo, los logits de salida deberían tener todas magnitudes similares. Es decir, es un mono tirando probabilidades sin tener idea y todos los caracteres deberiajn tener mas o menos la misma probabilidad o dentro de un rango acotado de probabilidades\n",
        "\n",
        "Para confirmar esto, calculamos exponencial de la pérdida media, que deberia ser aproximadamente igual al tamaño del vocabulario.\n",
        "\n",
        "Una pérdida mucho más alta significa que el modelo está seguro de sus respuestas incorrectas y está mal inicializado"
      ],
      "metadata": {
        "id": "vkvUIneTFiow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f837a391-d3d3-430e-ef91-cfd1a13ef719",
        "execution": {
          "iopub.status.busy": "2023-06-08T17:27:58.399154Z",
          "iopub.execute_input": "2023-06-08T17:27:58.399512Z",
          "iopub.status.idle": "2023-06-08T17:27:58.406466Z",
          "shell.execute_reply.started": "2023-06-08T17:27:58.399483Z",
          "shell.execute_reply": "2023-06-08T17:27:58.405491Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 105,
          "output_type": "execute_result",
          "data": {
            "text/plain": "47.98785"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Otras funciones de pérdida\n",
        "\n",
        "* tf.keras.losses.BinaryCrossentropy: Esta sería una elección apropiada para un problema de clasificación binaria\n",
        "\n",
        "* tf.keras.losses.MeanSquaredError: Esta se usaría típicamente para problemas de regresión\n",
        "\n",
        "* tf.keras.losses.CategoricalCrossentropy: Esta sería una elección apropiada para un problema de clasificación multiclase en el que las etiquetas han sido codificadas en one-hot"
      ],
      "metadata": {
        "id": "fyZ84GLEj4A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizador"
      ],
      "metadata": {
        "id": "V4kboK_bj9M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=loss)"
      ],
      "metadata": {
        "id": "DDl1_Een6rL0",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T17:48:02.622402Z",
          "iopub.execute_input": "2023-06-08T17:48:02.622759Z",
          "iopub.status.idle": "2023-06-08T17:48:02.635911Z",
          "shell.execute_reply.started": "2023-06-08T17:48:02.622729Z",
          "shell.execute_reply": "2023-06-08T17:48:02.634904Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Otros Optimizadores\n",
        "\n",
        "* tf.keras.optimizers.SGD: Este es el optimizador de descenso de gradiente estocástico. Es más simple que Adam y ha estado en uso por más tiempo.\n",
        "\n",
        "* tf.keras.optimizers.RMSprop: Este optimizador también es una opción popular y funciona bien en muchos casos.\n",
        "\n",
        "* tf.keras.optimizers.Adagrad y tf.keras.optimizers.Adadelta son otras dos opciones."
      ],
      "metadata": {
        "id": "jeOXriLcymww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurar checkpoints"
      ],
      "metadata": {
        "id": "ieSJdchZggUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos `tf.keras.callbacks.ModelCheckpoint` para guardar los checkpoints durante el entrenamiento"
      ],
      "metadata": {
        "id": "C6XBUUavgF56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"./training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix, save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "W6fWTriUZP-n",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T17:48:05.530934Z",
          "iopub.execute_input": "2023-06-08T17:48:05.531942Z",
          "iopub.status.idle": "2023-06-08T17:48:05.537773Z",
          "shell.execute_reply.started": "2023-06-08T17:48:05.531905Z",
          "shell.execute_reply": "2023-06-08T17:48:05.536790Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamos el modelo"
      ],
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class TqdmProgressCallback(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.epochs = self.params['epochs']\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.current_epoch = epoch  # Guarda el número de la época actual\n",
        "        self.pbar = tqdm(total=self.params['steps'], unit='step')\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.pbar.update()\n",
        "        self.pbar.set_description(f\"Epoch {self.current_epoch+1}/{self.epochs} \\\n",
        "                 Loss: {logs.get('loss'):.3f}\")\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.pbar.close()\n",
        "\n",
        "callbacks = [TqdmProgressCallback()]   # checkpoint_callback\n",
        "history = model.fit(dataset, epochs=6, callbacks=callbacks, verbose=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-08T18:08:13.558609Z",
          "iopub.execute_input": "2023-06-08T18:08:13.558973Z",
          "iopub.status.idle": "2023-06-08T18:14:24.160471Z",
          "shell.execute_reply.started": "2023-06-08T18:08:13.558941Z",
          "shell.execute_reply": "2023-06-08T18:14:24.159366Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "24c425c651b64ac1bea5f96eaf8cc0be",
            "f02fa0c128d64eb5bda9705251ca127a",
            "f9ae6e79a36d40a797bb716b29c40b71",
            "60dbf49dfd8e4e08babb492de73c4f2d",
            "03907b0a93cb4472a8a5eeb3a460e59d",
            "e15b4d4d63fc420598e1df0e733e1918"
          ]
        },
        "id": "SXqy-dE4347Z",
        "outputId": "d7e2d1be-3912-4a14-fb1e-b2fccffe1643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/81 [00:00<?, ?step/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24c425c651b64ac1bea5f96eaf8cc0be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/81 [00:00<?, ?step/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02fa0c128d64eb5bda9705251ca127a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/81 [00:00<?, ?step/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9ae6e79a36d40a797bb716b29c40b71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/81 [00:00<?, ?step/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60dbf49dfd8e4e08babb492de73c4f2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/81 [00:00<?, ?step/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03907b0a93cb4472a8a5eeb3a460e59d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/81 [00:00<?, ?step/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e15b4d4d63fc420598e1df0e733e1918"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/kaggle/working/training_checkpoints\"\n",
        "for file_name in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-08T18:15:53.496946Z",
          "iopub.execute_input": "2023-06-08T18:15:53.497398Z",
          "iopub.status.idle": "2023-06-08T18:15:54.154034Z",
          "shell.execute_reply.started": "2023-06-08T18:15:53.497357Z",
          "shell.execute_reply": "2023-06-08T18:15:54.153032Z"
        },
        "trusted": true,
        "id": "vMkpOEmy347Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('modelLSTM.pickle', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-08T18:15:59.235401Z",
          "iopub.execute_input": "2023-06-08T18:15:59.235755Z",
          "iopub.status.idle": "2023-06-08T18:16:00.255433Z",
          "shell.execute_reply.started": "2023-06-08T18:15:59.235723Z",
          "shell.execute_reply": "2023-06-08T18:16:00.251918Z"
        },
        "trusted": true,
        "id": "E84WiObU347a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generar texto"
      ],
      "metadata": {
        "id": "kKkD5M6eoSiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.model = model\n",
        "        self.chars_from_ids = chars_from_ids\n",
        "        self.ids_from_chars = ids_from_chars\n",
        "\n",
        "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
        "        sparse_mask = tf.SparseTensor(\n",
        "            values=[-float(\"inf\")] * len(skip_ids),\n",
        "            indices=skip_ids,\n",
        "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
        "        )\n",
        "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "    @tf.function\n",
        "    def generate_one_step(self, inputs, states=None):\n",
        "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
        "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "        predicted_logits, states = self.model(\n",
        "            inputs=input_ids, states=states, return_state=True\n",
        "        )\n",
        "        predicted_logits = predicted_logits[:, -1, :]\n",
        "        predicted_logits = predicted_logits / self.temperature\n",
        "        predicted_logits = predicted_logits + self.prediction_mask\n",
        "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "        return predicted_chars, states"
      ],
      "metadata": {
        "id": "iSBU1tHmlUSs",
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-06-08T18:14:24.162830Z",
          "iopub.execute_input": "2023-06-08T18:14:24.163299Z",
          "iopub.status.idle": "2023-06-08T18:14:24.174495Z",
          "shell.execute_reply.started": "2023-06-08T18:14:24.163262Z",
          "shell.execute_reply": "2023-06-08T18:14:24.173433Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a  50%\n",
        "b  20%\n",
        "c  10%\n",
        "d  1%\n",
        "e  1%\n",
        "f  1%\n"
      ],
      "metadata": {
        "id": "6mAGSUkDCX-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.05)\n",
        "\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant([\"los paises crecen porque \"])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(180):\n",
        "    next_char, states = one_step_model.generate_one_step(\n",
        "        next_char, states=states\n",
        "    )\n",
        "    result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
        "print(\"\\nRun time:\", end - start)"
      ],
      "metadata": {
        "id": "ST7PSyk9t1mT",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac86e86d-1e80-4d11-82cb-719d45372121",
        "execution": {
          "iopub.status.busy": "2023-06-08T18:14:41.672150Z",
          "iopub.execute_input": "2023-06-08T18:14:41.673158Z",
          "iopub.status.idle": "2023-06-08T18:14:43.088453Z",
          "shell.execute_reply.started": "2023-06-08T18:14:41.673115Z",
          "shell.execute_reply": "2023-06-08T18:14:43.087529Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "los paises crecen porque las variaciones en la demanda de dinero para las transacciones de cambio ordinarias de la  vida económica hace que el patrón oro no se emplea e mercancía para la compra en toda pos \n\n________________________________________________________________________________\n\nRun time: 1.3826918601989746\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}